{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d309d48",
   "metadata": {
    "_cell_guid": "75cfcbab-8ea2-47ef-b506-5323cbc50db2",
    "_uuid": "7ab9e7c4-89c1-4ba1-9d32-1cd7e560ee70",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-26T12:32:57.497434Z",
     "iopub.status.busy": "2025-08-26T12:32:57.497060Z",
     "iopub.status.idle": "2025-08-26T12:34:19.936019Z",
     "shell.execute_reply": "2025-08-26T12:34:19.934777Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 82.444241,
     "end_time": "2025-08-26T12:34:19.937658",
     "exception": false,
     "start_time": "2025-08-26T12:32:57.493417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading enriched comments from /kaggle/input/data-cleaning/comments_enriched.parquet\n",
      "[INFO] Computing fundamentals for 39938 videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39938/39938 [00:46<00:00, 852.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Adding video metadata for saturation metrics...\n",
      "[INFO] Loaded video metadata from: /kaggle/input/datathon-loreal/videos.csv\n",
      "[INFO] Added saturation metrics\n",
      "[INFO] Computing normalized health scores...\n",
      "\n",
      "==================================================\n",
      "FUNDAMENTAL METRICS SUMMARY\n",
      "==================================================\n",
      "Total videos processed: 39938\n",
      "\n",
      "Key Metrics Distribution:\n",
      "  engagement_ratio: median=0.333, 90th=2.599\n",
      "  commenter_depth: median=0.800, 90th=0.989\n",
      "  saturation: median=0.705, 90th=3.511\n",
      "  fundamental_health: median=0.270, 90th=0.419\n",
      "\n",
      "Top 10 Healthiest Videos:\n",
      " videoId  fundamental_health  engagement_ratio  commenter_depth  saturation\n",
      "   56370            0.793179         12.783784         0.986486    0.890744\n",
      "   46891            0.791929         23.264039         0.999015    1.190961\n",
      "   68937            0.789461         29.285541         0.998785    1.631215\n",
      "   60732            0.789085         19.130926         0.997743    2.263150\n",
      "   30730            0.788618         17.916988         0.998069    0.824309\n",
      "   48889            0.787276         20.305699         0.994819    2.238571\n",
      "   18125            0.786344         11.393387         0.999325   24.824835\n",
      "   39396            0.785586         21.595506         0.994382    0.656769\n",
      "   92521            0.779706         38.053146         0.999575    1.155415\n",
      "    5933            0.779697          9.969697         0.969697    1.109532\n",
      "\n",
      "[OK] Saved fundamental metrics → /kaggle/working/signal_fundamentals.csv\n",
      "\n",
      "==============================\n",
      "VALIDATION\n",
      "==============================\n",
      "✓ Health score range: [0.150, 0.793]\n",
      "✓ Mean health score: 0.291\n",
      "✓ Correlation with comments: 0.215\n",
      "\n",
      "[DONE] Fundamental metrics computation complete!\n"
     ]
    }
   ],
   "source": [
    "# --- CELL: fundamentals.py ---\n",
    "# Compute fundamental health metrics for each video\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ====== CONFIG ======\n",
    "INPUT  = \"/kaggle/input/data-cleaning/comments_enriched.parquet\"\n",
    "OUTPUT = \"/kaggle/working/signal_fundamentals.csv\"\n",
    "# ===================\n",
    "\n",
    "print(f\"[INFO] Loading enriched comments from {INPUT}\")\n",
    "df = pd.read_parquet(INPUT)\n",
    "\n",
    "# Validate required columns\n",
    "required_cols = [\"videoId\", \"text_norm\", \"likeCount\", \"emoji_count\", \"hashtags\", \"lang\"]\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    raise KeyError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "print(f\"[INFO] Computing fundamentals for {df['videoId'].nunique()} videos...\")\n",
    "\n",
    "# ---- COMPUTE FUNDAMENTAL METRICS ----\n",
    "fundamental_metrics = []\n",
    "\n",
    "# Group by video\n",
    "video_groups = df.groupby(\"videoId\")\n",
    "\n",
    "for vid, group in tqdm(video_groups, total=len(video_groups)):\n",
    "    # Basic counts\n",
    "    total_comments = len(group)\n",
    "    total_likes = group[\"likeCount\"].sum()\n",
    "    unique_commenters = group[\"commentId\"].nunique() if \"commentId\" in group.columns else total_comments\n",
    "    \n",
    "    # Engagement metrics\n",
    "    engagement_ratio = total_likes / (total_comments + 1)  # likes per comment\n",
    "    \n",
    "    # Diversity metrics\n",
    "    commenter_depth = unique_commenters / (total_comments + 1)  # unique users per comment\n",
    "    \n",
    "    # Content quality metrics\n",
    "    avg_emojis = group[\"emoji_count\"].mean()\n",
    "    total_emojis = group[\"emoji_count\"].sum()\n",
    "    \n",
    "    # Hashtag usage\n",
    "    hashtag_lists = group[\"hashtags\"].dropna()\n",
    "    total_hashtags = sum(len(tags) for tags in hashtag_lists if isinstance(tags, list))\n",
    "    avg_hashtags_per_comment = total_hashtags / (total_comments + 1)\n",
    "    \n",
    "    # Language diversity (if available)\n",
    "    if \"lang\" in group.columns:\n",
    "        lang_diversity = group[\"lang\"].nunique() / (total_comments + 1)\n",
    "    else:\n",
    "        lang_diversity = 0.0\n",
    "    \n",
    "    # Text quality (length and complexity)\n",
    "    text_lengths = group[\"text_norm\"].str.len().fillna(0)\n",
    "    avg_text_length = text_lengths.mean()\n",
    "    \n",
    "    # Saturation metrics (requires viewCount from video metadata)\n",
    "    # We'll compute this later if metadata is available\n",
    "    \n",
    "    fundamental_metrics.append({\n",
    "        \"videoId\": int(vid),\n",
    "        \"total_comments\": int(total_comments),\n",
    "        \"total_likes\": int(total_likes),\n",
    "        \"unique_commenters\": int(unique_commenters),\n",
    "        \"engagement_ratio\": float(engagement_ratio),\n",
    "        \"commenter_depth\": float(commenter_depth),\n",
    "        \"avg_emojis_per_comment\": float(avg_emojis),\n",
    "        \"total_emojis\": int(total_emojis),\n",
    "        \"avg_hashtags_per_comment\": float(avg_hashtags_per_comment),\n",
    "        \"lang_diversity\": float(lang_diversity),\n",
    "        \"avg_text_length\": float(avg_text_length)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "fund_df = pd.DataFrame(fundamental_metrics)\n",
    "\n",
    "# ---- ADD VIDEO METADATA (if available) ----\n",
    "print(\"[INFO] Adding video metadata for saturation metrics...\")\n",
    "\n",
    "try:\n",
    "    # Try to load video metadata\n",
    "    video_meta_paths = [\n",
    "        \"/kaggle/input/datathon-loreal/videos.csv\",\n",
    "        \"/kaggle/working/videos.csv\",\n",
    "        \"/kaggle/input/data-cleaning/videos.csv\"\n",
    "    ]\n",
    "    \n",
    "    video_meta = None\n",
    "    import glob\n",
    "    \n",
    "    for path_pattern in video_meta_paths:\n",
    "        matches = glob.glob(path_pattern)\n",
    "        if matches:\n",
    "            video_meta = pd.read_csv(matches[0])\n",
    "            print(f\"[INFO] Loaded video metadata from: {matches[0]}\")\n",
    "            break\n",
    "    \n",
    "    if video_meta is not None:\n",
    "        # Ensure videoId consistency\n",
    "        video_meta[\"videoId\"] = video_meta[\"videoId\"].astype(fund_df[\"videoId\"].dtype)\n",
    "        \n",
    "        # Merge viewCount\n",
    "        fund_df = fund_df.merge(\n",
    "            video_meta[[\"videoId\", \"viewCount\"]].rename(columns={\"viewCount\": \"video_viewCount\"}),\n",
    "            on=\"videoId\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        \n",
    "        # Compute saturation (comments per 1000 views)\n",
    "        fund_df[\"saturation\"] = (\n",
    "            fund_df[\"total_comments\"] / (fund_df[\"video_viewCount\"] / 1000 + 1)\n",
    "        ).fillna(0)\n",
    "        \n",
    "        print(\"[INFO] Added saturation metrics\")\n",
    "    else:\n",
    "        print(\"[WARN] No video metadata found, skipping saturation metrics\")\n",
    "        fund_df[\"saturation\"] = 0.0\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Failed to load video metadata: {e}\")\n",
    "    fund_df[\"saturation\"] = 0.0\n",
    "\n",
    "# ---- NORMALIZE METRICS ----\n",
    "print(\"[INFO] Computing normalized health scores...\")\n",
    "\n",
    "# Engagement quality score (0-1)\n",
    "# Higher engagement ratio = better, but cap at reasonable level\n",
    "engagement_normalized = np.clip(fund_df[\"engagement_ratio\"] / 10, 0, 1)  # Assume 10 likes/comment is max good\n",
    "fund_df[\"engagement_quality\"] = engagement_normalized\n",
    "\n",
    "# Commenter depth score (0-1)\n",
    "# Higher diversity = better\n",
    "fund_df[\"depth_score\"] = np.clip(fund_df[\"commenter_depth\"], 0, 1)\n",
    "\n",
    "# Content richness score (combines emojis, hashtags, text length)\n",
    "richness_score = (\n",
    "    0.4 * np.clip(fund_df[\"avg_emojis_per_comment\"] / 5, 0, 1) +  # Max 5 emojis/comment\n",
    "    0.3 * np.clip(fund_df[\"avg_hashtags_per_comment\"] / 3, 0, 1) +  # Max 3 hashtags/comment\n",
    "    0.3 * np.clip(fund_df[\"avg_text_length\"] / 200, 0, 1)  # Max 200 chars/comment\n",
    ")\n",
    "fund_df[\"content_richness\"] = richness_score\n",
    "\n",
    "# Overall health score\n",
    "fund_df[\"fundamental_health\"] = (\n",
    "    0.4 * fund_df[\"engagement_quality\"] +\n",
    "    0.3 * fund_df[\"depth_score\"] +\n",
    "    0.3 * fund_df[\"content_richness\"]\n",
    ")\n",
    "\n",
    "# ---- SUMMARY ----\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FUNDAMENTAL METRICS SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Total videos processed: {len(fund_df)}\")\n",
    "\n",
    "print(f\"\\nKey Metrics Distribution:\")\n",
    "metrics = [\"engagement_ratio\", \"commenter_depth\", \"saturation\", \"fundamental_health\"]\n",
    "for metric in metrics:\n",
    "    if metric in fund_df.columns:\n",
    "        p50 = fund_df[metric].median()\n",
    "        p90 = fund_df[metric].quantile(0.9)\n",
    "        print(f\"  {metric}: median={p50:.3f}, 90th={p90:.3f}\")\n",
    "\n",
    "print(f\"\\nTop 10 Healthiest Videos:\")\n",
    "top_health = fund_df.nlargest(10, \"fundamental_health\")[[\n",
    "    \"videoId\", \"fundamental_health\", \"engagement_ratio\", \"commenter_depth\", \"saturation\"\n",
    "]]\n",
    "print(top_health.to_string(index=False))\n",
    "\n",
    "# ---- SAVE ----\n",
    "fund_df.to_csv(OUTPUT, index=False)\n",
    "print(f\"\\n[OK] Saved fundamental metrics → {OUTPUT}\")\n",
    "\n",
    "# ---- VALIDATION ----\n",
    "print(f\"\\n\" + \"=\"*30)\n",
    "print(\"VALIDATION\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "if len(fund_df) > 0:\n",
    "    print(f\"✓ Health score range: [{fund_df['fundamental_health'].min():.3f}, {fund_df['fundamental_health'].max():.3f}]\")\n",
    "    print(f\"✓ Mean health score: {fund_df['fundamental_health'].mean():.3f}\")\n",
    "    print(f\"✓ Correlation with comments: {fund_df[['total_comments', 'fundamental_health']].corr().iloc[0,1]:.3f}\")\n",
    "else:\n",
    "    print(\"✗ No data to validate\")\n",
    "\n",
    "print(\"\\n[DONE] Fundamental metrics computation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8128629,
     "sourceId": 12851871,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 258022563,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 91.811376,
   "end_time": "2025-08-26T12:34:23.365425",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-26T12:32:51.554049",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
